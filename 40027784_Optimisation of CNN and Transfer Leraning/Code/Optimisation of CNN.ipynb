{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yDaav7zQImZh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import models,layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GXOangoHImZk"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VEMh6CMrImZk",
    "outputId": "a7c3e8b3-2ce0-46f1-b64c-0a31b926e102"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape,X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUqGY_iMImZl"
   },
   "source": [
    "# data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUPXAtQWImZm",
    "outputId": "8b3e5be5-28a9-4855-e96e-87aa48671b03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, ..., 9, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1,)\n",
    "y_test = y_test.reshape(-1,)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "joXh8o3AImZm",
    "outputId": "3f939c46-edbf-458f-987d-b650453b2f1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1df38e8a400>"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ijYsKR6Zt8Vb",
    "outputId": "a8bc1093-ea4e-498a-e0e5-8ef5813807d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "id": "ZDFsQOOauA58"
   },
   "outputs": [],
   "source": [
    "labels = {'Airplane':0, 'Automobile':1, 'Bird':2, 'Cat':3, 'Deer':4, 'Dog':5, 'Frog':6, 'Horse':7, 'Ship':8,'Truck':9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwlKX25xtnw-",
    "outputId": "d7642164-c2ae-4dbe-f98c-19bf9c1db34e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5000\n",
       "1    5000\n",
       "2    5000\n",
       "3    5000\n",
       "4    5000\n",
       "5    5000\n",
       "6    5000\n",
       "7    5000\n",
       "8    5000\n",
       "9    5000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1000\n",
       "1    1000\n",
       "2    1000\n",
       "3    1000\n",
       "4    1000\n",
       "5    1000\n",
       "6    1000\n",
       "7    1000\n",
       "8    1000\n",
       "9    1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZOKp6k1ImZn"
   },
   "source": [
    "# Normalising data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1qJ2mdotImZn"
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Eb5tdsQN9Gu",
    "outputId": "743db5d2-37ea-4c3d-aede-ba3b8c8c4f95"
   },
   "outputs": [],
   "source": [
    "labels = dict(zip(labels.values(),labels.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Airplane',\n",
       " 1: 'Automobile',\n",
       " 2: 'Bird',\n",
       " 3: 'Cat',\n",
       " 4: 'Deer',\n",
       " 5: 'Dog',\n",
       " 6: 'Frog',\n",
       " 7: 'Horse',\n",
       " 8: 'Ship',\n",
       " 9: 'Truck'}"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "id": "I_wF7izEQhgs"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\40027784\\AppData\\Local\\Temp\\ipykernel_31224\\38986147.py\", line 44, in <lambda>\n",
      "    classify_b=Button(top,text=\"Classify Image\",command=lambda: classify(file_path),padx=10,pady=5)\n",
      "  File \"C:\\Users\\40027784\\AppData\\Local\\Temp\\ipykernel_31224\\38986147.py\", line 32, in classify\n",
      "    img1=np.array(img)\n",
      "NameError: name 'np' is not defined\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "import numpy\n",
    "#load the trained model to classify sign\n",
    "from keras.models import load_model\n",
    "model = load_model('cnn10.h5')\n",
    "#dictionary to label all traffic signs class.\n",
    "classes = {0: 'Airplane',\n",
    " 1: 'Automobile',\n",
    " 2: 'Bird',\n",
    " 3: 'Cat',\n",
    " 4: 'Deer',\n",
    " 5: 'Dog',\n",
    " 6: 'Frog',\n",
    " 7: 'Horse',\n",
    " 8: 'Ship',\n",
    " 9: 'Truck'}\n",
    "#initialise GUI\n",
    "top=tk.Tk()\n",
    "top.geometry('800x600')\n",
    "top.title('Image classification')\n",
    "top.configure(background='#CDCDCD')\n",
    "label=Label(top,background='#CDCDCD', font=('arial',15,'bold'))\n",
    "sign_image = Label(top)\n",
    "# print(sign_image)\n",
    "\n",
    "def classify(file_path):\n",
    "    img = Image.open(file_path)\n",
    "    img=img.resize((32,32))\n",
    "    img1=np.array(img)\n",
    "    img1=np.reshape(img1,[-1, 32, 32, 3])\n",
    "    img1=img1.astype('float')\n",
    "    img1/=255\n",
    "    pred = model.predict([img1])[0]\n",
    "    print(pred)\n",
    "    #     sign = classes[pred+1]\n",
    "    sign=classes[max(range(len(pred)), key = lambda x: pred[x])]\n",
    "    print(sign)\n",
    "    label.configure(foreground='#011638', text=sign)\n",
    "    \n",
    "def show_classify_button(file_path):\n",
    "    classify_b=Button(top,text=\"Classify Image\",command=lambda: classify(file_path),padx=10,pady=5)\n",
    "    classify_b.configure(background='#364156', foreground='white',font=('arial',10,'bold'))\n",
    "    classify_b.place(relx=0.79,rely=0.46)\n",
    "def upload_image():\n",
    "    try:\n",
    "        file_path=filedialog.askopenfilename()\n",
    "        uploaded=Image.open(file_path)\n",
    "        uploaded.thumbnail(((top.winfo_width()/2.25),(top.winfo_height()/2.25)))\n",
    "        im=ImageTk.PhotoImage(uploaded)\n",
    "        sign_image.configure(image=im)\n",
    "        sign_image.image=im\n",
    "        label.configure(text='')\n",
    "        show_classify_button(file_path)\n",
    "    except:\n",
    "        pass\n",
    "upload=Button(top,text=\"Upload an image\",command=upload_image,padx=10,pady=5)\n",
    "upload.configure(background='#364156', foreground='white',font=('arial',10,'bold'))\n",
    "upload.pack(side=BOTTOM,pady=50)\n",
    "sign_image.pack(side=BOTTOM,expand=True)\n",
    "label.pack(side=BOTTOM,expand=True)\n",
    "heading = Label(top, text=\"Upload Image to Classify\",pady=20, font=('arial',20,'bold'))\n",
    "heading.configure(background='#CDCDCD',foreground='#364156')\n",
    "heading.pack()\n",
    "top.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn10=load_model('cnn10.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2.9.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.test.is_built_with_cuda()\n",
    "print(tf.version.VERSION)\n",
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 1.4126 - accuracy: 0.4853 - val_loss: 1.1102 - val_accuracy: 0.6022\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.9679 - accuracy: 0.6599 - val_loss: 0.9595 - val_accuracy: 0.6637\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.7820 - accuracy: 0.7236 - val_loss: 0.8550 - val_accuracy: 0.7006\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.6587 - accuracy: 0.7688 - val_loss: 0.7479 - val_accuracy: 0.7394\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.5647 - accuracy: 0.8019 - val_loss: 0.7318 - val_accuracy: 0.7527\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.4803 - accuracy: 0.8309 - val_loss: 0.7707 - val_accuracy: 0.7517\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.4101 - accuracy: 0.8576 - val_loss: 0.7619 - val_accuracy: 0.7595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29b21f64a00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn10 = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same',\n",
    "                  input_shape=(32,32,3)),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same',\n",
    "                  input_shape=(32,32,3)),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Conv2D(filters=128, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.Conv2D(filters=128, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation=\"relu\"),\n",
    "    layers.Dense(10,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "cnn10.compile(\n",
    "   optimizer=\"adam\",\n",
    "   loss=\"sparse_categorical_crossentropy\",\n",
    "   metrics=[\"accuracy\"]\n",
    "\n",
    ")\n",
    "callback=tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=2)\n",
    "cnn10.fit(X_train, y_train, epochs = 15, batch_size=64, validation_data=(X_test, y_test), verbose= 1,callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn10.save('cnn11.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 1.4718 - accuracy: 0.4632 - val_loss: 1.1425 - val_accuracy: 0.5945 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.9989 - accuracy: 0.6455 - val_loss: 0.9483 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.7957 - accuracy: 0.7191 - val_loss: 0.8125 - val_accuracy: 0.7199 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.6663 - accuracy: 0.7679 - val_loss: 0.8434 - val_accuracy: 0.7165 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.5676 - accuracy: 0.8013 - val_loss: 0.7501 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.4876 - accuracy: 0.8298 - val_loss: 0.7406 - val_accuracy: 0.7518 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.4084 - accuracy: 0.8575 - val_loss: 0.7877 - val_accuracy: 0.7509 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.3478 - accuracy: 0.8782 - val_loss: 0.8847 - val_accuracy: 0.7487 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1531 - accuracy: 0.9498 - val_loss: 0.8793 - val_accuracy: 0.7736 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.1025 - accuracy: 0.9688 - val_loss: 0.9538 - val_accuracy: 0.7706 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29b385e0b20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn10 = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same',\n",
    "                  input_shape=(32,32,3)),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same',\n",
    "                  input_shape=(32,32,3)),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Conv2D(filters=128, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.Conv2D(filters=128, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation=\"relu\"),\n",
    "    layers.Dense(10,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "cnn10.compile(\n",
    "   optimizer=\"adam\",\n",
    "   loss=\"sparse_categorical_crossentropy\",\n",
    "   metrics=[\"accuracy\"]\n",
    "\n",
    ")\n",
    "callback=tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=2)\n",
    "lr=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',patience=3)\n",
    "cnn10.fit(X_train, y_train, epochs = 10, batch_size=64, validation_data=(X_test, y_test), verbose= 1,callbacks=[lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn10.save('cnn12.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch,lr):\n",
    "    if epoch not in [5,10,15,20]:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "lr1=tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 1.4552 - accuracy: 0.4711 - val_loss: 1.0900 - val_accuracy: 0.6058 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.9759 - accuracy: 0.6561 - val_loss: 0.9335 - val_accuracy: 0.6705 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.7751 - accuracy: 0.7300 - val_loss: 0.8139 - val_accuracy: 0.7183 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.6549 - accuracy: 0.7708 - val_loss: 0.7548 - val_accuracy: 0.7397 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.5542 - accuracy: 0.8048 - val_loss: 0.7322 - val_accuracy: 0.7548 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.4534 - accuracy: 0.8416 - val_loss: 0.7787 - val_accuracy: 0.7486 - lr: 9.0484e-04\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.3882 - accuracy: 0.8629 - val_loss: 0.7361 - val_accuracy: 0.7673 - lr: 9.0484e-04\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.3163 - accuracy: 0.8887 - val_loss: 0.8671 - val_accuracy: 0.7500 - lr: 9.0484e-04\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.2716 - accuracy: 0.9036 - val_loss: 0.9048 - val_accuracy: 0.7555 - lr: 9.0484e-04\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.2298 - accuracy: 0.9192 - val_loss: 0.9105 - val_accuracy: 0.7597 - lr: 9.0484e-04\n"
     ]
    }
   ],
   "source": [
    "cnn10 = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same',\n",
    "                  input_shape=(32,32,3)),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same',\n",
    "                  input_shape=(32,32,3)),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Conv2D(filters=128, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.Conv2D(filters=128, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation=\"relu\"),\n",
    "    layers.Dense(10,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "cnn10.compile(\n",
    "   optimizer=\"adam\",\n",
    "   loss=\"sparse_categorical_crossentropy\",\n",
    "   metrics=[\"accuracy\"]\n",
    "\n",
    ")\n",
    "callback=tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=3)\n",
    "lr=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',patience=2)\n",
    "h=cnn10.fit(X_train, y_train, epochs = 20, batch_size=64, validation_data=(X_test, y_test), verbose= 1,callbacks=[lr1,callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn10.save('cnn13.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 1.4231 - accuracy: 0.4813 - val_loss: 1.2220 - val_accuracy: 0.5687 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.9725 - accuracy: 0.6545 - val_loss: 0.9702 - val_accuracy: 0.6566 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.7722 - accuracy: 0.7285 - val_loss: 0.8882 - val_accuracy: 0.6866 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.6507 - accuracy: 0.7717 - val_loss: 0.7384 - val_accuracy: 0.7507 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.5681 - accuracy: 0.8011 - val_loss: 0.7420 - val_accuracy: 0.7482 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.4623 - accuracy: 0.8371 - val_loss: 0.7375 - val_accuracy: 0.7594 - lr: 9.0484e-04\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.3923 - accuracy: 0.8613 - val_loss: 0.7975 - val_accuracy: 0.7526 - lr: 9.0484e-04\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.3310 - accuracy: 0.8832 - val_loss: 0.8257 - val_accuracy: 0.7551 - lr: 9.0484e-04\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.2797 - accuracy: 0.8994 - val_loss: 0.8572 - val_accuracy: 0.7523 - lr: 9.0484e-04\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.2287 - accuracy: 0.9186 - val_loss: 0.9103 - val_accuracy: 0.7613 - lr: 9.0484e-04\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1733 - accuracy: 0.9383 - val_loss: 1.0439 - val_accuracy: 0.7636 - lr: 8.1873e-04\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1498 - accuracy: 0.9460 - val_loss: 1.1129 - val_accuracy: 0.7557 - lr: 8.1873e-04\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1402 - accuracy: 0.9512 - val_loss: 1.1531 - val_accuracy: 0.7618 - lr: 8.1873e-04\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1269 - accuracy: 0.9549 - val_loss: 1.2783 - val_accuracy: 0.7529 - lr: 8.1873e-04\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1142 - accuracy: 0.9600 - val_loss: 1.2427 - val_accuracy: 0.7534 - lr: 8.1873e-04\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0946 - accuracy: 0.9664 - val_loss: 1.3950 - val_accuracy: 0.7578 - lr: 7.4082e-04\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0862 - accuracy: 0.9705 - val_loss: 1.4322 - val_accuracy: 0.7451 - lr: 7.4082e-04\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0859 - accuracy: 0.9700 - val_loss: 1.4029 - val_accuracy: 0.7530 - lr: 7.4082e-04\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0792 - accuracy: 0.9725 - val_loss: 1.4564 - val_accuracy: 0.7581 - lr: 7.4082e-04\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0798 - accuracy: 0.9721 - val_loss: 1.4650 - val_accuracy: 0.7507 - lr: 7.4082e-04\n"
     ]
    }
   ],
   "source": [
    "cnn10 = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same',input_shape=(32,32,3)),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same',input_shape=(32,32,3)),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Conv2D(filters=128, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.Conv2D(filters=128, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation=\"relu\"),\n",
    "    layers.Dense(10,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "cnn10.compile(\n",
    "   optimizer=\"adam\",\n",
    "   loss=\"sparse_categorical_crossentropy\",\n",
    "   metrics=[\"accuracy\"]\n",
    "\n",
    ")\n",
    "chk=tf.keras.callbacks.ModelCheckpoint(filepath='Checkpoint2/checkpoint',mode='max',monitor='val_accuracy',\n",
    "                                       save_best_only=True,save_weights_only=True)\n",
    "callback=tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=1,mode='max')\n",
    "lr=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',patience=2)\n",
    "h=cnn10.fit(X_train, y_train, epochs = 20, batch_size=64, validation_data=(X_test, y_test), verbose= 1,callbacks=[lr1,chk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 8, 8, ..., 5, 1, 7], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result8 = cnn10.predict(X_test)\n",
    "res8 = np.argmax(result8,axis=1)\n",
    "res8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7507"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(res8,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x29b45d37ee0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn10.load_weights('Checkpoint2/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 8, 8, ..., 5, 1, 7], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result8 = cnn10.predict(X_test)\n",
    "res8 = np.argmax(result8,axis=1)\n",
    "res8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7636"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(res8,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn10.save('cnn14.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 10s 11ms/step - loss: 1.4322 - accuracy: 0.4764 - val_loss: 1.1480 - val_accuracy: 0.5875 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.9581 - accuracy: 0.6618 - val_loss: 0.8540 - val_accuracy: 0.6996 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.7564 - accuracy: 0.7354 - val_loss: 0.7715 - val_accuracy: 0.7345 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.6348 - accuracy: 0.7777 - val_loss: 0.8119 - val_accuracy: 0.7220 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.5353 - accuracy: 0.8121 - val_loss: 0.7276 - val_accuracy: 0.7597 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.4549 - accuracy: 0.8395 - val_loss: 0.7426 - val_accuracy: 0.7613 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.3828 - accuracy: 0.8660 - val_loss: 0.7867 - val_accuracy: 0.7566 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.3180 - accuracy: 0.8883 - val_loss: 0.7795 - val_accuracy: 0.7601 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1343 - accuracy: 0.9573 - val_loss: 0.8386 - val_accuracy: 0.7900 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0848 - accuracy: 0.9746 - val_loss: 0.9049 - val_accuracy: 0.7908 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29b3fbbb040>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn10 = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same',input_shape=(32,32,3)),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same',input_shape=(32,32,3)),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Conv2D(filters=128, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.Conv2D(filters=128, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation=\"relu\"),\n",
    "    layers.Dense(10,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "cnn10.compile(\n",
    "   optimizer=\"adam\",\n",
    "   loss=\"sparse_categorical_crossentropy\",\n",
    "   metrics=[\"accuracy\"]\n",
    "\n",
    ")\n",
    "callback=tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=2)\n",
    "lr=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',patience=2)\n",
    "cnn10.fit(X_train, y_train, epochs = 10, batch_size=64, validation_data=(X_test, y_test), verbose= 1,callbacks=[lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn10.save('cnn15.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.reset_memory_stats(\n",
    "    'GPU:0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 1.4118 - accuracy: 0.4881 - val_loss: 1.1155 - val_accuracy: 0.6079 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.9567 - accuracy: 0.6636 - val_loss: 0.9193 - val_accuracy: 0.6721 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.7728 - accuracy: 0.7293 - val_loss: 0.8291 - val_accuracy: 0.7147 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.6518 - accuracy: 0.7716 - val_loss: 0.7622 - val_accuracy: 0.7398 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.5532 - accuracy: 0.8048 - val_loss: 0.7748 - val_accuracy: 0.7404 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.4730 - accuracy: 0.8339 - val_loss: 0.7573 - val_accuracy: 0.7540 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.4009 - accuracy: 0.8586 - val_loss: 0.8079 - val_accuracy: 0.7461 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.3402 - accuracy: 0.8797 - val_loss: 0.8683 - val_accuracy: 0.7464 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.1521 - accuracy: 0.9513 - val_loss: 0.8721 - val_accuracy: 0.7787 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.1003 - accuracy: 0.9692 - val_loss: 0.9473 - val_accuracy: 0.7762 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.0735 - accuracy: 0.9795 - val_loss: 1.0205 - val_accuracy: 0.7790 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0523 - accuracy: 0.9876 - val_loss: 1.1254 - val_accuracy: 0.7774 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0364 - accuracy: 0.9925 - val_loss: 1.2129 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0210 - accuracy: 0.9976 - val_loss: 1.2355 - val_accuracy: 0.7774 - lr: 1.0000e-05\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0189 - accuracy: 0.9979 - val_loss: 1.2601 - val_accuracy: 0.7768 - lr: 1.0000e-05\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0172 - accuracy: 0.9984 - val_loss: 1.2634 - val_accuracy: 0.7770 - lr: 1.0000e-06\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0171 - accuracy: 0.9985 - val_loss: 1.2664 - val_accuracy: 0.7773 - lr: 1.0000e-06\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0169 - accuracy: 0.9985 - val_loss: 1.2667 - val_accuracy: 0.7773 - lr: 1.0000e-07\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.0168 - accuracy: 0.9985 - val_loss: 1.2671 - val_accuracy: 0.7772 - lr: 1.0000e-07\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.0168 - accuracy: 0.9985 - val_loss: 1.2671 - val_accuracy: 0.7772 - lr: 1.0000e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29b48d58220>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn10 = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same',input_shape=(32,32,3)),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same',input_shape=(32,32,3)),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Conv2D(filters=128, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.Conv2D(filters=128, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation=\"relu\"),\n",
    "    layers.Dense(10,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "cnn10.compile(\n",
    "   optimizer=\"adam\",\n",
    "   loss=\"sparse_categorical_crossentropy\",\n",
    "   metrics=[\"accuracy\"]\n",
    "\n",
    ")\n",
    "chk=tf.keras.callbacks.ModelCheckpoint(filepath='Checkpoint3/checkpoint',mode='max',monitor='val_accuracy',\n",
    "                                       save_best_only=True,save_weights_only=True)\n",
    "lr=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',patience=2)\n",
    "cnn10.fit(X_train, y_train, epochs = 20, batch_size=64, validation_data=(X_test, y_test), verbose= 1,callbacks=[lr,chk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h.history['loss'])\n",
    "plt.plot(h.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x29b48a98790>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn10.load_weights('Checkpoint3/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.779"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result9 = cnn10.predict(X_test)\n",
    "res9 = np.argmax(result9,axis=1)\n",
    "accuracy_score(y_test,res9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn10.save('cnn16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 1.4675 - accuracy: 0.4666 - val_loss: 1.1527 - val_accuracy: 0.5899 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.9975 - accuracy: 0.6496 - val_loss: 0.9582 - val_accuracy: 0.6734 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.7927 - accuracy: 0.7237 - val_loss: 0.7878 - val_accuracy: 0.7263 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.6632 - accuracy: 0.7674 - val_loss: 0.7892 - val_accuracy: 0.7282 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.5630 - accuracy: 0.8043 - val_loss: 0.7500 - val_accuracy: 0.7471 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.4814 - accuracy: 0.8318 - val_loss: 0.7837 - val_accuracy: 0.7448 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.4079 - accuracy: 0.8553 - val_loss: 0.7483 - val_accuracy: 0.7582 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.3455 - accuracy: 0.8772 - val_loss: 0.8424 - val_accuracy: 0.7522 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.2906 - accuracy: 0.8966 - val_loss: 0.8846 - val_accuracy: 0.7488 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21678cd00d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn10 = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same',input_shape=(32,32,3)),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same',input_shape=(32,32,3)),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Conv2D(filters=128, kernel_size=(3, 3),activation=\"relu\",kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.Conv2D(filters=128, kernel_size=(3, 3),activation='relu',kernel_initializer='he_uniform',padding='same'),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation=\"relu\"),\n",
    "    layers.Dense(10,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "cnn10.compile(\n",
    "   optimizer=\"adam\",\n",
    "   loss=\"sparse_categorical_crossentropy\",\n",
    "   metrics=[\"accuracy\"]\n",
    "\n",
    ")\n",
    "chk=tf.keras.callbacks.ModelCheckpoint(filepath='Checkpoint4/checkpoint',mode='max',monitor='val_accuracy',\n",
    "                                       save_best_only=True,save_weights_only=True)\n",
    "callback=tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=2)\n",
    "lr=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',patience=2)\n",
    "cnn10.fit(X_train, y_train, epochs = 20, batch_size=64, validation_data=(X_test, y_test), verbose= 1,callbacks=[lr,chk,callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn10.save('cnn17.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model=Sequential()\n",
    "    \n",
    "    #Buiding the convolutional layer\n",
    "    model.add(Conv2D(filters=32,kernel_size=hp.Choice('kernel_size_1',values=[3,5]),\n",
    "                     kernel_initializer='he_uniform',padding='same',activation='relu',input_shape=(32,32,3)))\n",
    "    model.add(Conv2D(filters=32,kernel_size=hp.Choice('kernel_size_2',values=[3,5]),\n",
    "                     kernel_initializer='he_uniform',padding='same',activation='relu',input_shape=(32,32,3)))\n",
    "    model.add(MaxPooling2D(pool_size=hp.Choice('pool_1',values=[2,3])))\n",
    "    \n",
    "    #2nd \n",
    "    model.add(Conv2D(filters=64,kernel_size=hp.Choice('kernel_size_3',values=[3,5]),\n",
    "                     kernel_initializer='he_uniform',padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=64,kernel_size=hp.Choice('kernel_size_4',values=[3,5]),\n",
    "                     kernel_initializer='he_uniform',padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=hp.Choice('pool_2',values=[2,3]))) \n",
    "    \n",
    "    #3rd\n",
    "    model.add(Conv2D(filters=128,kernel_size=hp.Choice('kernel_size_5',values=[3,5]),\n",
    "                     kernel_initializer='he_uniform',padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=128,kernel_size=hp.Choice('kernel_size_6',values=[3,5]),\n",
    "                     kernel_initializer='he_uniform',padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=hp.Choice('pool_3',values=[2,3])))\n",
    "    \n",
    "    #Flattening the feature map\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #Adding ANN layers \n",
    "    model.add(Dense(units=hp.Int('Unit_1',min_value=64,max_value=256,step=16),activation='relu'))\n",
    "   \n",
    "    #adding the final layer\n",
    "    model.add(Dense(units=10,activation='softmax'))\n",
    "\n",
    "    #compiling the model\n",
    "    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner=RandomSearch(build_model,\n",
    "                   objective='val_accuracy',\n",
    "                   max_trials=3,overwrite=True\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 41s]\n",
      "val_accuracy: 0.7350000143051147\n",
      "\n",
      "Best val_accuracy So Far: 0.7350000143051147\n",
      "Total elapsed time: 00h 02m 02s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train,y_train,epochs=3,validation_split=0.2,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        51264     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 5, 5, 128)         204928    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 5, 5, 128)         409728    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 1, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 80)                10320     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                810       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 724,122\n",
      "Trainable params: 724,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6262 - accuracy: 0.7819 - val_loss: 0.7361 - val_accuracy: 0.7467\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5070 - accuracy: 0.8241 - val_loss: 0.7125 - val_accuracy: 0.7646\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.4135 - accuracy: 0.8568 - val_loss: 0.7506 - val_accuracy: 0.7561\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.3370 - accuracy: 0.8822 - val_loss: 0.8394 - val_accuracy: 0.7567\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.2780 - accuracy: 0.9028 - val_loss: 0.8364 - val_accuracy: 0.7599\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.2320 - accuracy: 0.9185 - val_loss: 0.8875 - val_accuracy: 0.7623\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.2038 - accuracy: 0.9292 - val_loss: 0.9710 - val_accuracy: 0.7547\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.1845 - accuracy: 0.9363 - val_loss: 1.0098 - val_accuracy: 0.7624\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.1729 - accuracy: 0.9404 - val_loss: 1.0963 - val_accuracy: 0.7556\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.1520 - accuracy: 0.9483 - val_loss: 1.1260 - val_accuracy: 0.7663\n"
     ]
    }
   ],
   "source": [
    "answer=model.fit(X_train,y_train,epochs=10,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('hyp1cnn10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model=Sequential()\n",
    "    #Buiding the convolutional layer\n",
    "    model.add(Conv2D(filters=hp.Int('filter_1',min_value=16,max_value=256,step=16),\n",
    "                     kernel_size=hp.Choice('kernel_size_1',values=[3,5]),\n",
    "                     kernel_initializer='he_uniform',padding='same',activation='relu',input_shape=(32,32,3)))\n",
    "    model.add(Conv2D(filters=hp.Int('filter_2',min_value=16,max_value=256,step=16),\n",
    "                     kernel_size=hp.Choice('kernel_size_2',values=[3,5]),\n",
    "                     kernel_initializer='he_uniform',padding='same',activation='relu',input_shape=(32,32,3)))\n",
    "    model.add(MaxPooling2D(pool_size=hp.Choice('pool_1',values=[2,3])))\n",
    "    \n",
    "    #2nd \n",
    "    model.add(Conv2D(filters=hp.Int('filter_3',min_value=16,max_value=256,step=16),\n",
    "                     kernel_size=hp.Choice('kernel_size_3',values=[3,5]),\n",
    "                     kernel_initializer='he_uniform',padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=hp.Int('filter_4',min_value=16,max_value=256,step=16),\n",
    "                     kernel_size=hp.Choice('kernel_size_4',values=[3,5]),\n",
    "                     kernel_initializer='he_uniform',padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=hp.Choice('pool_2',values=[2,3]))) \n",
    "    \n",
    "    #3rd\n",
    "    model.add(Conv2D(filters=hp.Int('filter_5',min_value=16,max_value=256,step=16),\n",
    "                     kernel_size=hp.Choice('kernel_size_5',values=[3,5]),\n",
    "                     kernel_initializer='he_uniform',padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=hp.Int('filter_6',min_value=16,max_value=256,step=16),\n",
    "                     kernel_size=hp.Choice('kernel_size_6',values=[3,5]),\n",
    "                     kernel_initializer='he_uniform',padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=hp.Choice('pool_3',values=[2,3])))\n",
    "    \n",
    "    #Flattening the feature map\n",
    "    model.add(Flatten())\n",
    "    #Adding ANN layers \n",
    "    model.add(Dense(units=hp.Int('Unit_1',min_value=64,max_value=256,step=16),activation='relu'))\n",
    "    #adding the final layer\n",
    "    model.add(Dense(units=10,activation='softmax'))\n",
    "    #compiling the model\n",
    "    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 01m 34s]\n",
      "val_accuracy: 0.6669999957084656\n",
      "\n",
      "Best val_accuracy So Far: 0.7419999837875366\n",
      "Total elapsed time: 00h 04m 03s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner=RandomSearch(build_model,\n",
    "                   objective='val_accuracy',\n",
    "                   max_trials=3,\n",
    "                   overwrite=True\n",
    "                  )\n",
    "tuner.search(X_train,y_train,epochs=3,validation_data=(X_test,y_test),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 128)       102528    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 144)       166032    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 224)       806624    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 224)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 96)          537696    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 176)         422576    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 2, 176)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 704)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 80)                56400     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                810       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,093,562\n",
      "Trainable params: 2,093,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tuner.get_best_models(num_models=1)[0]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.5772 - accuracy: 0.8011 - val_loss: 0.7109 - val_accuracy: 0.7572\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.4693 - accuracy: 0.8380 - val_loss: 0.6823 - val_accuracy: 0.7727\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.3814 - accuracy: 0.8673 - val_loss: 0.7452 - val_accuracy: 0.7682\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.3135 - accuracy: 0.8895 - val_loss: 0.9798 - val_accuracy: 0.7343\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.2630 - accuracy: 0.9096 - val_loss: 0.8945 - val_accuracy: 0.7564\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.2282 - accuracy: 0.9219 - val_loss: 0.8714 - val_accuracy: 0.7642\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1992 - accuracy: 0.9318 - val_loss: 0.9830 - val_accuracy: 0.7780\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1867 - accuracy: 0.9366 - val_loss: 1.0072 - val_accuracy: 0.7581\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.1636 - accuracy: 0.9439 - val_loss: 1.0033 - val_accuracy: 0.7787\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1577 - accuracy: 0.9472 - val_loss: 1.0060 - val_accuracy: 0.7787\n"
     ]
    }
   ],
   "source": [
    "chk=tf.keras.callbacks.ModelCheckpoint(filepath='Checkpoint5/checkpoint',mode='max',monitor='val_accuracy',\n",
    "                                       save_best_only=True,save_weights_only=True)\n",
    "answer=model.fit(X_train,y_train,epochs=10,validation_data=(X_test,y_test),callbacks=chk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('hyp2cnn10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model=Sequential()\n",
    "\n",
    "    #Buiding the convolutional layer\n",
    "    model.add(Conv2D(filters=hp.Int('filter_1',min_value=16,max_value=256,step=16),\n",
    "                     kernel_size=hp.Choice('kernel_size_1',values=[3,5]),\n",
    "                     kernel_initializer='he_uniform',padding='same',activation='relu',input_shape=(32,32,3)))\n",
    "    model.add(Conv2D(filters=hp.Int('filter_2',min_value=16,max_value=256,step=16),\n",
    "                     kernel_size=hp.Choice('kernel_size_2',values=[3,5]),\n",
    "                     kernel_initializer='he_uniform',padding='same',activation='relu',input_shape=(32,32,3)))\n",
    "    model.add(MaxPooling2D(pool_size=hp.Choice('pool_1',values=[2,3])))\n",
    "    \n",
    "    #2nd \n",
    "    model.add(Conv2D(filters=hp.Int('filter_3',min_value=16,max_value=256,step=16),\n",
    "                     kernel_size=hp.Choice('kernel_size_3',values=[3,5]),\n",
    "                     kernel_initializer='he_uniform',padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=hp.Int('filter_4',min_value=16,max_value=256,step=16),\n",
    "                     kernel_size=hp.Choice('kernel_size_4',values=[3,5]),\n",
    "                     kernel_initializer='he_uniform',padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=hp.Choice('pool_2',values=[2,3]))) \n",
    "    \n",
    "    #3rd\n",
    "    model.add(Conv2D(filters=hp.Int('filter_5',min_value=16,max_value=256,step=16),\n",
    "                     kernel_size=hp.Choice('kernel_size_5',values=[3,5]),\n",
    "                     kernel_initializer='he_uniform',padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=hp.Int('filter_6',min_value=16,max_value=256,step=16),\n",
    "                     kernel_size=hp.Choice('kernel_size_6',values=[3,5]),\n",
    "                     kernel_initializer='he_uniform',padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=hp.Choice('pool_3',values=[2,3])))\n",
    "    \n",
    "    \n",
    "\n",
    "    #Flattening the feature map\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #Adding ANN layers \n",
    "    model.add(Dense(units=hp.Int('Unit_1',min_value=64,max_value=256,step=16),activation='relu'))\n",
    "   \n",
    "    #adding the final layer\n",
    "    model.add(Dense(units=10,activation='softmax'))\n",
    "    \n",
    "    adam=tf.keras.optimizers.Adam(learning_rate=hp.Choice('leraning_rate1',values=[0.01,0.001,0.0001,1.0e-5,1.0e-6]))\n",
    "    #compiling the model\n",
    "    model.compile(optimizer=adam,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 01m 05s]\n",
      "val_accuracy: 0.33500000834465027\n",
      "\n",
      "Best val_accuracy So Far: 0.33500000834465027\n",
      "Total elapsed time: 00h 04m 36s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner=RandomSearch(build_model,\n",
    "                   objective='val_accuracy',\n",
    "                   max_trials=3,\n",
    "                   overwrite=True\n",
    "                  )\n",
    "tuner.search(X_train,y_train,epochs=3,validation_data=(X_test,y_test),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 Complete [00h 02m 40s]\n",
      "val_accuracy: 0.7914999723434448\n",
      "\n",
      "Best val_accuracy So Far: 0.7914999723434448\n",
      "Total elapsed time: 00h 16m 24s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    model=load_model('cnn15.h5')\n",
    "    adam=tf.keras.optimizers.Adam(learning_rate=hp.Choice('leraning_rate1',values=[0.01,0.001,0.0001,1.0e-5,1.0e-6,\n",
    "                                                                                   1.0e-7,1.0e-8]))\n",
    "    model.compile(optimizer=adam,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner=RandomSearch(build_model,\n",
    "                   objective='val_accuracy',\n",
    "                   max_trials=7,\n",
    "                   overwrite=True\n",
    "                  )\n",
    "tuner.search(X_train,y_train,epochs=10,validation_data=(X_test,y_test),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_102 (Conv2D)         (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_103 (Conv2D)         (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPoolin  (None, 10, 10, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_104 (Conv2D)         (None, 10, 10, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_105 (Conv2D)         (None, 10, 10, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPoolin  (None, 3, 3, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_106 (Conv2D)         (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_107 (Conv2D)         (None, 3, 3, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_53 (MaxPoolin  (None, 1, 1, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 295,914\n",
      "Trainable params: 295,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tuner.get_best_models(num_models=1)[0]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('hyp3cnn15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "cnn15=load_model('cnn15.h5')\n",
    "hypcnn15=load_model('hyp3cnn15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7908"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result9 = cnn15.predict(X_test)\n",
    "res9 = np.argmax(result9,axis=1)\n",
    "accuracy_score(y_test,res9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7915"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result9 = hypcnn15.predict(X_test)\n",
    "res9 = np.argmax(result9,axis=1)\n",
    "accuracy_score(y_test,res9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\40027784\\AppData\\Local\\Temp\\ipykernel_31224\\2267754497.py\", line 44, in <lambda>\n",
      "    classify_b=Button(top,text=\"Classify Image\",command=lambda: classify(file_path),padx=10,pady=5)\n",
      "  File \"C:\\Users\\40027784\\AppData\\Local\\Temp\\ipykernel_31224\\2267754497.py\", line 32, in classify\n",
      "    img1=np.array(img)\n",
      "NameError: name 'np' is not defined\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "import numpy\n",
    "#load the trained model to classify sign\n",
    "from keras.models import load_model\n",
    "model = load_model('hyp3cnn15.h5')\n",
    "#dictionary to label all traffic signs class.\n",
    "classes = {0: 'Airplane',\n",
    " 1: 'Automobile',\n",
    " 2: 'Bird',\n",
    " 3: 'Cat',\n",
    " 4: 'Deer',\n",
    " 5: 'Dog',\n",
    " 6: 'Frog',\n",
    " 7: 'Horse',\n",
    " 8: 'Ship',\n",
    " 9: 'Truck'}\n",
    "#initialise GUI\n",
    "top=tk.Tk()\n",
    "top.geometry('800x600')\n",
    "top.title('Image classification')\n",
    "top.configure(background='#0000FF')\n",
    "label=Label(top,background='#CDCDCD', font=('arial',15,'bold'))\n",
    "sign_image = Label(top)\n",
    "# print(sign_image)\n",
    "\n",
    "def classify(file_path):\n",
    "    img = Image.open(file_path)\n",
    "    img=img.resize((32,32))\n",
    "    img1=np.array(img)\n",
    "    img1=np.reshape(img1,[-1, 32, 32, 3])\n",
    "    img1=img1.astype('float')\n",
    "    img1/=255\n",
    "    pred = model.predict([img1])[0]\n",
    "    print(pred)\n",
    "    #     sign = classes[pred+1]\n",
    "    sign=classes[max(range(len(pred)), key = lambda x: pred[x])]\n",
    "    print(sign)\n",
    "    label.configure(foreground='#011638', text=sign)\n",
    "    \n",
    "def show_classify_button(file_path):\n",
    "    classify_b=Button(top,text=\"Classify Image\",command=lambda: classify(file_path),padx=10,pady=5)\n",
    "    classify_b.configure(background='#364156', foreground='white',font=('arial',10,'bold'))\n",
    "    classify_b.place(relx=0.79,rely=0.46)\n",
    "def upload_image():\n",
    "    try:\n",
    "        file_path=filedialog.askopenfilename()\n",
    "        uploaded=Image.open(file_path)\n",
    "        uploaded.thumbnail(((top.winfo_width()/2.25),(top.winfo_height()/2.25)))\n",
    "        im=ImageTk.PhotoImage(uploaded)\n",
    "        sign_image.configure(image=im)\n",
    "        sign_image.image=im\n",
    "        label.configure(text='')\n",
    "        show_classify_button(file_path)\n",
    "    except:\n",
    "        pass\n",
    "upload=Button(top,text=\"Upload an image\",command=upload_image,padx=10,pady=5)\n",
    "upload.configure(background='#364156', foreground='white',font=('arial',10,'bold'))\n",
    "upload.pack(side=BOTTOM,pady=50)\n",
    "sign_image.pack(side=BOTTOM,expand=True)\n",
    "label.pack(side=BOTTOM,expand=True)\n",
    "heading = Label(top, text=\"Upload Image to Classify\",pady=20, font=('arial',20,'bold'))\n",
    "heading.configure(background='#CDCDCD',foreground='#364156')\n",
    "heading.pack()\n",
    "top.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar10-dataset.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
