{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2a8fefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import models,layers\n",
    "import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import models,layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d99ca4bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_img' from 'keras.preprocessing.image' (C:\\Users\\40027784\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\preprocessing\\image.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D,Dense,Dropout, Flatten,Activation, BatchNormalization,MaxPooling2D\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets, layers, models\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_img\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m img_to_array\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'load_img' from 'keras.preprocessing.image' (C:\\Users\\40027784\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\preprocessing\\image.py)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import PIL\n",
    "import pathlib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Dense,Dropout, Flatten,Activation, BatchNormalization,MaxPooling2D\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d807d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\40027784\\Downloads\\archive\\PetImages\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/40027784/Downloads/archive/PetImages/Cat/0.jpg'),\n",
       " WindowsPath('C:/Users/40027784/Downloads/archive/PetImages/Cat/1.jpg'),\n",
       " WindowsPath('C:/Users/40027784/Downloads/archive/PetImages/Cat/10.jpg'),\n",
       " WindowsPath('C:/Users/40027784/Downloads/archive/PetImages/Cat/100.jpg'),\n",
       " WindowsPath('C:/Users/40027784/Downloads/archive/PetImages/Cat/1000.jpg')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = pathlib.Path(\"C:\\\\Users\\\\40027784\\\\Downloads\\\\archive\\\\PetImages\")\n",
    "print(data_dir)\n",
    "list(data_dir.glob('*/*.jpg'))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2cad8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/40027784/Downloads/archive/PetImages/Dog/0.jpg'),\n",
       " WindowsPath('C:/Users/40027784/Downloads/archive/PetImages/Dog/1.jpg'),\n",
       " WindowsPath('C:/Users/40027784/Downloads/archive/PetImages/Dog/10.jpg'),\n",
       " WindowsPath('C:/Users/40027784/Downloads/archive/PetImages/Dog/100.jpg'),\n",
       " WindowsPath('C:/Users/40027784/Downloads/archive/PetImages/Dog/1000.jpg')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs = list(data_dir.glob('Dog/*'))\n",
    "dogs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea7dfcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/40027784/Downloads/archive/PetImages/Cat/0.jpg'),\n",
       " WindowsPath('C:/Users/40027784/Downloads/archive/PetImages/Cat/1.jpg'),\n",
       " WindowsPath('C:/Users/40027784/Downloads/archive/PetImages/Cat/10.jpg'),\n",
       " WindowsPath('C:/Users/40027784/Downloads/archive/PetImages/Cat/100.jpg'),\n",
       " WindowsPath('C:/Users/40027784/Downloads/archive/PetImages/Cat/1000.jpg')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = list(data_dir.glob('Cat/*'))\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ced93b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d3415cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_images_dict = {\n",
    "    'cats': list(data_dir.glob('Cat/*')),\n",
    "    'dogs': list(data_dir.glob('Dog/*')),\n",
    "}\n",
    "\n",
    "pet_labels_dict = {\n",
    "    'cats': 3,\n",
    "    'dogs': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba62f413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats\n",
      "dogs\n"
     ]
    }
   ],
   "source": [
    "IMAGE_WIDTH=32\n",
    "IMAGE_HEIGHT=32\n",
    "X, Y = [], []\n",
    "\n",
    "for pet_name, images in pet_images_dict.items():\n",
    "    print(pet_name)\n",
    "    for image in images:\n",
    "        img = cv2.imread(str(image))\n",
    "        if isinstance(img,type(None)): \n",
    "            #print('image not found')\n",
    "            continue\n",
    "            \n",
    "        elif ((img.shape[0] >= IMAGE_HEIGHT) and  (img.shape[1] >=IMAGE_WIDTH)):\n",
    "            resized_img = cv2.resize(img,(IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "            X.append(resized_img)\n",
    "            Y.append(pet_labels_dict[pet_name])\n",
    "        else:\n",
    "            #print(\"Invalid Image\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "192edd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7346ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08cd14a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18708 18708\n",
      "6237 6237\n",
      "(18708, 32, 32, 3) (18708,)\n",
      "(6237, 32, 32, 3) (6237,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0)\n",
    "print(len(X_train),len(Y_train))\n",
    "print(len(X_test),len(Y_test))\n",
    "\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e962f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0f0acde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('cnn15.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf371ad7",
   "metadata": {},
   "source": [
    "# epoch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40465f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "585/585 [==============================] - 29s 49ms/step - loss: 0.5760 - accuracy: 0.7425 - val_loss: 0.5008 - val_accuracy: 0.7622\n",
      "Epoch 2/3\n",
      "585/585 [==============================] - 29s 49ms/step - loss: 0.4281 - accuracy: 0.8023 - val_loss: 0.4835 - val_accuracy: 0.7715\n",
      "Epoch 3/3\n",
      "585/585 [==============================] - 29s 50ms/step - loss: 0.3806 - accuracy: 0.8273 - val_loss: 0.5029 - val_accuracy: 0.7635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dad224dc40>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=3,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "daece44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2047"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3 = model.predict(X_test)\n",
    "res3 = np.argmax(result3,axis=1)\n",
    "accuracy_score(y_test,res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02e27ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('retrained3cnn15.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b9727b",
   "metadata": {},
   "source": [
    "# epoch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0e31197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "585/585 [==============================] - 30s 50ms/step - loss: 0.5762 - accuracy: 0.7427 - val_loss: 0.4921 - val_accuracy: 0.7694\n",
      "Epoch 2/5\n",
      "585/585 [==============================] - 29s 50ms/step - loss: 0.4243 - accuracy: 0.8053 - val_loss: 0.4732 - val_accuracy: 0.7795\n",
      "Epoch 3/5\n",
      "585/585 [==============================] - 30s 52ms/step - loss: 0.3761 - accuracy: 0.8345 - val_loss: 0.4668 - val_accuracy: 0.7837\n",
      "Epoch 4/5\n",
      "585/585 [==============================] - 31s 53ms/step - loss: 0.3362 - accuracy: 0.8532 - val_loss: 0.4670 - val_accuracy: 0.7888\n",
      "Epoch 5/5\n",
      "585/585 [==============================] - 29s 49ms/step - loss: 0.2957 - accuracy: 0.8748 - val_loss: 0.4750 - val_accuracy: 0.7940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dad0f40cd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=5,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36d79075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1681"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3 = model.predict(X_test)\n",
    "res3 = np.argmax(result3,axis=1)\n",
    "accuracy_score(y_test,res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26837677",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('retrained2cnn15.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4784a0",
   "metadata": {},
   "source": [
    "# 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e1fcc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "585/585 [==============================] - 7s 11ms/step - loss: 0.5728 - accuracy: 0.7466 - val_loss: 0.4951 - val_accuracy: 0.7621\n",
      "Epoch 2/10\n",
      "585/585 [==============================] - 6s 11ms/step - loss: 0.4238 - accuracy: 0.8039 - val_loss: 0.4739 - val_accuracy: 0.7810\n",
      "Epoch 3/10\n",
      "585/585 [==============================] - 6s 11ms/step - loss: 0.3758 - accuracy: 0.8323 - val_loss: 0.4721 - val_accuracy: 0.7872\n",
      "Epoch 4/10\n",
      "585/585 [==============================] - 7s 11ms/step - loss: 0.3354 - accuracy: 0.8506 - val_loss: 0.4719 - val_accuracy: 0.7896\n",
      "Epoch 5/10\n",
      "585/585 [==============================] - 7s 11ms/step - loss: 0.2951 - accuracy: 0.8735 - val_loss: 0.4705 - val_accuracy: 0.7924\n",
      "Epoch 6/10\n",
      "585/585 [==============================] - 6s 11ms/step - loss: 0.2548 - accuracy: 0.8954 - val_loss: 0.4830 - val_accuracy: 0.7916\n",
      "Epoch 7/10\n",
      "585/585 [==============================] - 7s 12ms/step - loss: 0.2130 - accuracy: 0.9182 - val_loss: 0.5129 - val_accuracy: 0.7930\n",
      "Epoch 8/10\n",
      "585/585 [==============================] - 7s 11ms/step - loss: 0.1715 - accuracy: 0.9399 - val_loss: 0.5542 - val_accuracy: 0.7884\n",
      "Epoch 9/10\n",
      "585/585 [==============================] - 7s 11ms/step - loss: 0.1318 - accuracy: 0.9580 - val_loss: 0.6095 - val_accuracy: 0.7799\n",
      "Epoch 10/10\n",
      "585/585 [==============================] - 7s 11ms/step - loss: 0.0942 - accuracy: 0.9748 - val_loss: 0.6537 - val_accuracy: 0.7869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x200c53726a0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=10,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c9cd816",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7ecd163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, ..., 9, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1,)\n",
    "y_test = y_test.reshape(-1,)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c658b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e455f4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 8, 3, ..., 5, 3, 5], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3 = model.predict(X_test)\n",
    "res3 = np.argmax(result3,axis=1)\n",
    "res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a36906c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1742"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f772383",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('retrainedcnn15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "789f0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "import numpy\n",
    "#load the trained model to classify sign\n",
    "from keras.models import load_model\n",
    "#model1 = load_model('hyp3cnn15.h5')\n",
    "#dictionary to label all traffic signs class.\n",
    "classes = {0: 'Airplane',\n",
    " 1: 'Automobile',\n",
    " 2: 'Bird',\n",
    " 3: 'Cat',\n",
    " 4: 'Deer',\n",
    " 5: 'Dog',\n",
    " 6: 'Frog',\n",
    " 7: 'Horse',\n",
    " 8: 'Ship',\n",
    " 9: 'Truck'}\n",
    "#initialise GUI\n",
    "top=tk.Tk()\n",
    "top.geometry('800x600')\n",
    "top.title('Image classification')\n",
    "top.configure(background='#F5F5F5')\n",
    "label=Label(top,background='#000000', font=('roboto',15,'bold'))\n",
    "sign_image = Label(top)\n",
    "# print(sign_image)\n",
    "\n",
    "def classify(file_path):\n",
    "    img = Image.open(file_path)\n",
    "    img=img.resize((32,32))\n",
    "    img1=np.array(img)\n",
    "    img1=np.reshape(img1,[-1, 32, 32, 3])\n",
    "    img1=img1.astype('float')\n",
    "    img1/=255\n",
    "    pred = model.predict([img1])[0]\n",
    "    print(pred)\n",
    "    #     sign = classes[pred+1]\n",
    "    sign=classes[max(range(len(pred)), key = lambda x: pred[x])]\n",
    "    print(sign)\n",
    "    label.configure(foreground='#011638', text=sign)\n",
    "    \n",
    "def show_classify_button(file_path):\n",
    "    classify_b=Button(top,text=\"Classify Image\",command=lambda: classify(file_path),padx=10,pady=5)\n",
    "    classify_b.configure(background='#364156', foreground='white',font=('roboto',10,'bold'))\n",
    "    classify_b.place(relx=0.79,rely=0.46)\n",
    "def upload_image():\n",
    "    try:\n",
    "        file_path=filedialog.askopenfilename()\n",
    "        uploaded=Image.open(file_path)\n",
    "        uploaded.thumbnail(((top.winfo_width()/2.25),(top.winfo_height()/2.25)))\n",
    "        im=ImageTk.PhotoImage(uploaded)\n",
    "        sign_image.configure(image=im)\n",
    "        sign_image.image=im\n",
    "        label.configure(text='')\n",
    "        show_classify_button(file_path)\n",
    "    except:\n",
    "        pass\n",
    "upload=Button(top,text=\"Upload an image\",command=upload_image,padx=10,pady=5)\n",
    "upload.configure(background='#364156', foreground='white',font=('roboto',10,'bold'))\n",
    "upload.pack(side=BOTTOM,pady=50)\n",
    "sign_image.pack(side=BOTTOM,expand=True)\n",
    "label.pack(side=BOTTOM,expand=True)\n",
    "heading = Label(top, text=\"Upload Image to Classify\",pady=20, font=('roboto',20,'bold'))\n",
    "heading.configure(background='#CDCDCD',foreground='#364156')\n",
    "heading.pack()\n",
    "top.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d56566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
